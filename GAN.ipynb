{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "## 创建文件夹\n",
    "os.makedirs(\"./images/gan/\", exist_ok=True)         ## 记录训练过程的图片效果\n",
    "os.makedirs(\"./save/gan/\", exist_ok=True)           ## 训练完成时模型保存的位置\n",
    "os.makedirs(\"./datasets/mnist\", exist_ok=True)      ## 下载数据集存放的位置\n",
    "\n",
    "## 超参数配置\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=2, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=500, help=\"interval betwen image samples\")\n",
    "opt = parser.parse_args()\n",
    "## opt = parser.parse_args(args=[])                 ## 在colab中运行时，换为此行\n",
    "print(opt)\n",
    "\n",
    "## 图像的尺寸:(1， 28， 28),  和图像的像素面积:(784)\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "img_area = np.prod(img_shape)\n",
    "\n",
    "## 设置cuda:(cuda:0)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "## mnist数据集下载\n",
    "mnist = datasets.MNIST(\n",
    "    root='./datasets/', train=True, download=True, transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ), \n",
    ")\n",
    "\n",
    "## 配置数据到加载器\n",
    "dataloader = DataLoader(\n",
    "    mnist,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "## ##### 定义判别器 Discriminator ######\n",
    "## 将图片28x28展开成784，然后通过多层感知器，中间经过斜率设置为0.2的LeakyReLU激活函数，\n",
    "## 最后接sigmoid激活函数得到一个0到1之间的概率进行二分类\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_area, 512),                   ## 输入特征数为784，输出为512\n",
    "            nn.LeakyReLU(0.2, inplace=True),            ## 进行非线性映射\n",
    "            nn.Linear(512, 256),                        ## 输入特征数为512，输出为256\n",
    "            nn.LeakyReLU(0.2, inplace=True),            ## 进行非线性映射\n",
    "            nn.Linear(256, 1),                          ## 输入特征数为256，输出为1\n",
    "            nn.Sigmoid(),                               ## sigmoid是一个激活函数，二分类问题中可将实数映射到[0, 1],作为概率值, 多分类用softmax函数\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)            ## 鉴别器输入是一个被view展开的(784)的一维图像:(64, 784)\n",
    "        validity = self.model(img_flat)                 ## 通过鉴别器网络\n",
    "        return validity                                 ## 鉴别器返回的是一个[0, 1]间的概率\n",
    "\n",
    "      \n",
    "## ###### 定义生成器 Generator #####\n",
    "## 输入一个100维的0～1之间的高斯分布，然后通过第一层线性变换将其映射到256维,\n",
    "## 然后通过LeakyReLU激活函数，接着进行一个线性变换，再经过一个LeakyReLU激活函数，\n",
    "## 然后经过线性变换将其变成784维，最后经过Tanh激活函数是希望生成的假的图片数据分布, 能够在-1～1之间。\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ## 模型中间块儿\n",
    "        def block(in_feat, out_feat, normalize=True):           ## block(in， out )\n",
    "            layers = [nn.Linear(in_feat, out_feat)]             ## 线性变换将输入映射到out维\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))    ## 正则化\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))      ## 非线性激活函数\n",
    "            return layers\n",
    "        ## prod():返回给定轴上的数组元素的乘积:1*28*28=784\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),       ## 线性变化将输入映射 100 to 128, 正则化, LeakyReLU\n",
    "            *block(128, 256),                                   ## 线性变化将输入映射 128 to 256, 正则化, LeakyReLU\n",
    "            *block(256, 512),                                   ## 线性变化将输入映射 256 to 512, 正则化, LeakyReLU\n",
    "            *block(512, 1024),                                  ## 线性变化将输入映射 512 to 1024, 正则化, LeakyReLU\n",
    "            nn.Linear(1024, img_area),                          ## 线性变化将输入映射 1024 to 784\n",
    "            nn.Tanh()                                           ## 将(784)的数据每一个都映射到[-1, 1]之间\n",
    "        )\n",
    "    ## view():相当于numpy中的reshape，重新定义矩阵的形状:这里是reshape(64, 1, 28, 28)\n",
    "    def forward(self, z):                                       ## 输入的是(64， 100)的噪声数据\n",
    "        imgs = self.model(z)                                     ## 噪声数据通过生成器模型\n",
    "        imgs = imgs.view(imgs.size(0), *img_shape)                 ## reshape成(64, 1, 28, 28)\n",
    "        return imgs                                              ## 输出为64张大小为(1, 28, 28)的图像\n",
    "\n",
    "\n",
    "## 创建生成器，判别器对象\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "## 首先需要定义loss的度量方式  （二分类的交叉熵）\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "## 其次定义 优化函数,优化函数的学习率为0.0003\n",
    "## betas:用于计算梯度以及梯度平方的运行平均值的系数\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "## 如果有显卡，都在cuda模式中运行\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "\n",
    "## ----------\n",
    "##  Training\n",
    "## ----------\n",
    "## 进行多个epoch的训练\n",
    "for epoch in range(opt.n_epochs):                               ## epoch:50\n",
    "    for i, (imgs, _) in enumerate(dataloader):                  ## imgs:(64, 1, 28, 28)     _:label(64)\n",
    "        \n",
    "        ## =============================训练判别器==================\n",
    "        ## view(): 相当于numpy中的reshape，重新定义矩阵的形状, 相当于reshape(128，784)  原来是(128, 1, 28, 28)\n",
    "        imgs = imgs.view(imgs.size(0), -1)                          ## 将图片展开为28*28=784  imgs:(64, 784)\n",
    "        real_img = Variable(imgs).cuda()                            ## 将tensor变成Variable放入计算图中，tensor变成variable之后才能进行反向传播求梯度\n",
    "        real_label = Variable(torch.ones(imgs.size(0), 1)).cuda()      ## 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(imgs.size(0), 1)).cuda()     ## 定义假的图片的label为0\n",
    "\n",
    "\n",
    "        ## ---------------------\n",
    "        ##  Train Discriminator\n",
    "        ## 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "        ## ---------------------\n",
    "        ## 计算真实图片的损失\n",
    "        real_out = discriminator(real_img)                          ## 将真实图片放入判别器中\n",
    "        loss_real_D = criterion(real_out, real_label)               ## 得到真实图片的loss\n",
    "        real_scores = real_out                                      ## 得到真实图片的判别值，输出的值越接近1越好\n",
    "        ## 计算假的图片的损失\n",
    "        ## detach(): 从当前计算图中分离下来避免梯度传到G，因为G不用更新\n",
    "        z = Variable(torch.randn(imgs.size(0), opt.latent_dim)).cuda()      ## 随机生成一些噪声, 大小为(128, 100)\n",
    "        fake_img = generator(z).detach()                                    ## 随机噪声放入生成网络中，生成一张假的图片。 \n",
    "        fake_out = discriminator(fake_img)                                  ## 判别器判断假的图片\n",
    "        loss_fake_D = criterion(fake_out, fake_label)                       ## 得到假的图片的loss\n",
    "        fake_scores = fake_out                                              ## 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "        ## 损失函数和优化\n",
    "        loss_D = loss_real_D + loss_fake_D                  ## 损失包括判真损失和判假损失\n",
    "        optimizer_D.zero_grad()                             ## 在反向传播之前，先将梯度归0\n",
    "        loss_D.backward()                                   ## 将误差反向传播\n",
    "        optimizer_D.step()                                  ## 更新参数\n",
    "\n",
    "\n",
    "        ## -----------------\n",
    "        ##  Train Generator\n",
    "        ## 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "        ## 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "        ## 反向传播更新的参数是生成网络里面的参数，\n",
    "        ## 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的, 这样就达到了对抗的目的\n",
    "        ## -----------------\n",
    "        z = Variable(torch.randn(imgs.size(0), opt.latent_dim)).cuda()      ## 得到随机噪声\n",
    "        fake_img = generator(z)                                             ## 随机噪声输入到生成器中，得到一副假的图片\n",
    "        output = discriminator(fake_img)                                    ## 经过判别器得到的结果\n",
    "        ## 损失函数和优化\n",
    "        loss_G = criterion(output, real_label)                              ## 得到的假的图片与真实的图片的label的loss\n",
    "        optimizer_G.zero_grad()                                             ## 梯度归0\n",
    "        loss_G.backward()                                                   ## 进行反向传播\n",
    "        optimizer_G.step()                                                  ## step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## 打印训练过程中的日志\n",
    "        ## item():取出单元素张量的元素值并返回该值，保持原元素类型不变\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [D real: %f] [D fake: %f]\"\n",
    "                % (epoch, opt.n_epochs, i, len(dataloader), loss_D.item(), loss_G.item(), real_scores.data.mean(), fake_scores.data.mean())\n",
    "            )\n",
    "        ## 保存训练过程中的图像\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            save_image(fake_img.data[:25], \"./images/gan/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "## 保存模型\n",
    "torch.save(generator.state_dict(), './save/gan/generator.pth')\n",
    "torch.save(discriminator.state_dict(), './save/gan/discriminator.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
