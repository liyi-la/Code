{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([69,  5, 61, 75, 19, 48, 90,  2, 13, 95, 30,  7, 51, 63,  6, 31, 98,  9,\n",
      "        33, 98, 84, 90, 96, 60, 79, 63, 49, 79,  7, 39, 77, 11])\n",
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    TimeEmbedding模块将把整型t，以Transformer函数式位置编码的方式，映射成向量，\n",
    "    其shape为(batch_size, time_channel)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_channels: int):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            n_channels：即time_channel\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
    "\n",
    "    def forward(self, t: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            t: 维度（batch_size），整型时刻t\n",
    "        \"\"\"\n",
    "        # 以下转换方法和Transformer的位置编码一致\n",
    "        # 【强烈建议大家动手跑一遍，打印出每一个步骤的结果和尺寸，更方便理解】\n",
    "        half_dim = self.n_channels // 8\n",
    "        emb = math.log(10_000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "\n",
    "        # Transform with the MLP\n",
    "        emb = self.act(self.lin1(emb))\n",
    "        emb = self.lin2(emb)\n",
    "\n",
    "        # 输出维度(batch_size, time_channels)\n",
    "        return emb\n",
    "    \n",
    "Timeebd = TimeEmbedding(32)\n",
    "t = torch.randint(0,100,(32,))\n",
    "print(t)\n",
    "print(Timeebd(t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather(alpha_bar, t):\n",
    "    return alpha_bar[t]\n",
    "\n",
    "class DenoiseDiffusion:\n",
    "    \"\"\"\n",
    "    Denoise Diffusion\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps_model: nn.Module, n_steps: int, device: torch.device):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            eps_model: UNet去噪模型，我们将在下文详细解读它的架构。\n",
    "            n_steps：训练总步数T\n",
    "            device：训练所用硬件\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 定义UNet架构模型\n",
    "        self.eps_model = eps_model\n",
    "        # 人为设置超参数beta，满足beta随着t的增大而增大，同时将beta搬运到训练硬件上\n",
    "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
    "        # 根据beta计算alpha（参见数学原理篇）\n",
    "        self.alpha = 1. - self.beta\n",
    "        # 根据alpha计算alpha_bar（参见数学原理篇）\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        # 定义训练总步长\n",
    "        self.n_steps = n_steps\n",
    "        # sampling中的sigma_t\n",
    "        self.sigma2 = self.beta\n",
    "\n",
    "    \n",
    "    def q_xt_x0(self, x0: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Diffusion Process的中间步骤，根据x0和t，推导出xt所服从的高斯分布的mean和var\n",
    "        Params:\n",
    "            x0：来自训练数据的干净的图片\n",
    "            t：某一步time_step\n",
    "        Return:\n",
    "            mean: xt所服从的高斯分布的均值\n",
    "            var：xt所服从的高斯分布的方差\n",
    "        \"\"\"\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # gather：人为定义的函数，从一连串超参中取出当前t对应的超参alpha_bar\n",
    "        # 由于xt = sqrt(alpha_bar_t) * x0 + sqrt(1-alpha_bar_t) * epsilon\n",
    "        # 其中epsilon~N(0, I)\n",
    "        # 因此根据高斯分布性质，xt~N(sqrt(alpha_bar_t) * x0, 1-alpha_bar_t)\n",
    "        # 即为本步中我们要求的mean和var\n",
    "        # ----------------------------------------------------------------\n",
    "        mean = gather(self.alpha_bar, t) ** 0.5 * x0\n",
    "        var = 1 - gather(self.alpha_bar, t)\n",
    "\n",
    "        return mean, var\n",
    "\n",
    "    def q_sample(self, x0: torch.Tensor, t: torch.Tensor, eps = None):\n",
    "        \"\"\"\n",
    "        Diffusion Process，根据xt所服从的高斯分布的mean和var，求出xt\n",
    "        Params:\n",
    "            x0：来自训练数据的干净的图片\n",
    "            t：某一步time_step\n",
    "        Return:\n",
    "            xt: 第t时刻加完噪声的图片\n",
    "        \"\"\"\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # xt = sqrt(alpha_bar_t) * x0 + sqrt(1-alpha_bar_t) * epsilon\n",
    "        #    = mean + sqrt(var) * epsilon\n",
    "        # 其中，epsilon~N(0, I)\n",
    "        # ----------------------------------------------------------------\n",
    "        if eps is None:\n",
    "            eps = torch.randn_like(x0)\n",
    "       \n",
    "        mean, var = self.q_xt_x0(x0, t)\n",
    "        return mean + (var ** 0.5) * eps#正向过程得到噪音\n",
    "\n",
    "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Sampling, 当模型训练好之后，根据x_t和t，推出x_{t-1}\n",
    "        Params:\n",
    "            x_t：t时刻的图片\n",
    "            t：某一步time_step\n",
    "        Return:\n",
    "            x_{t-1}: 第t-1时刻的图片\n",
    "        \"\"\"\n",
    "\n",
    "        # eps_model: 训练好的UNet去噪模型\n",
    "        # eps_theta: 用训练好的UNet去噪模型，预测第t步的噪声\n",
    "        eps_theta = self.eps_model(xt, t)\n",
    "        \n",
    "        # 根据Sampling提供的公式，推导出x_{t-1}\n",
    "        alpha_bar = gather(self.alpha_bar, t)       \n",
    "        alpha = gather(self.alpha, t)\n",
    "        eps_coef = (1 - alpha) / (1 - alpha_bar) ** .5\n",
    "        mean = 1 / (alpha ** 0.5) * (xt - eps_coef * eps_theta)\n",
    "        var = gather(self.sigma2, t)\n",
    "        eps = torch.randn(xt.shape, device=xt.device)\n",
    " \n",
    "        return mean + (var ** .5) * eps\n",
    "\n",
    "    def loss(self, x0: torch.Tensor, noise= None):\n",
    "        \"\"\"\n",
    "        1. 随机抽取一个time_step t\n",
    "        2. 执行diffusion process(q_sample)，随机生成噪声epsilon~N(0, I)，\n",
    "           然后根据x0, t和epsilon计算xt\n",
    "        3. 使用UNet去噪模型（p_sample），根据xt和t得到预测噪声epsilon_theta\n",
    "        4. 计算mse_loss(epsilon, epsilon_theta)\n",
    "        \n",
    "        【MSE只是众多可选loss设计中的一种，大家也可以自行设计loss函数】\n",
    "        \n",
    "        Params:\n",
    "            x0：来自训练数据的干净的图片\n",
    "            noise: diffusion process中随机抽样的噪声epsilon~N(0, I)\n",
    "        Return:\n",
    "            loss: 真实噪声和预测噪声之间的loss         \n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = x0.shape[0]\n",
    "        # 随机抽样t\n",
    "        t = torch.randint(0, self.n_steps, (batch_size,), device=x0.device, dtype=torch.long)#每个Batch随机选一个t\n",
    "        \n",
    "        # 如果为传入噪声，则从N(0, I)中抽样噪声\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "\n",
    "        # 执行Diffusion process，计算xt\n",
    "        xt = self.q_sample(x0, t, eps=noise)\n",
    "        # 执行Denoise Process，得到预测的噪声epsilon_theta\n",
    "        eps_theta = self.eps_model(xt, t)\n",
    "        \n",
    "        # 返回真实噪声和预测噪声之间的mse loss\n",
    "        return F.mse_loss(noise, eps_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999, 0.9996, 0.9992, 0.9986, 0.9978, 0.9969, 0.9958, 0.9946, 0.9932,\n",
      "        0.9916, 0.9898, 0.9879, 0.9859, 0.9836, 0.9812, 0.9787, 0.9760, 0.9732,\n",
      "        0.9702, 0.9670, 0.9637, 0.9603, 0.9567, 0.9529, 0.9490, 0.9450, 0.9408,\n",
      "        0.9365, 0.9321, 0.9275, 0.9228, 0.9180, 0.9130, 0.9079, 0.9027, 0.8974,\n",
      "        0.8919, 0.8864, 0.8807, 0.8749, 0.8690, 0.8630, 0.8569, 0.8507, 0.8444,\n",
      "        0.8380, 0.8316, 0.8250, 0.8184, 0.8116, 0.8048, 0.7979, 0.7910, 0.7839,\n",
      "        0.7768, 0.7697, 0.7624, 0.7552, 0.7478, 0.7404, 0.7330, 0.7255, 0.7180,\n",
      "        0.7104, 0.7028, 0.6951, 0.6875, 0.6798, 0.6720, 0.6643, 0.6565, 0.6487,\n",
      "        0.6409, 0.6331, 0.6252, 0.6174, 0.6095, 0.6017, 0.5939, 0.5860, 0.5782,\n",
      "        0.5704, 0.5625, 0.5547, 0.5470, 0.5392, 0.5315, 0.5237, 0.5160, 0.5084,\n",
      "        0.5007, 0.4931, 0.4856, 0.4780, 0.4705, 0.4631, 0.4556, 0.4483, 0.4409,\n",
      "        0.4337, 0.4264, 0.4192, 0.4121, 0.4050, 0.3980, 0.3910, 0.3841, 0.3773,\n",
      "        0.3705, 0.3637, 0.3571, 0.3504, 0.3439, 0.3374, 0.3310, 0.3247, 0.3184,\n",
      "        0.3122, 0.3060, 0.3000, 0.2940])\n"
     ]
    }
   ],
   "source": [
    "beta = torch.linspace(0.0001, 0.02, 121)\n",
    "        # 根据beta计算alpha（参见数学原理篇）\n",
    "alpha = 1. - beta\n",
    "        # 根据alpha计算alpha_bar（参见数学原理篇）\n",
    "alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "print(alpha_bar)    \n",
    "def gather(alpha_bar, t):\n",
    "    return alpha_bar[t]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
